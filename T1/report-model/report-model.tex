\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage[portuges,brazil,english]{babel}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Relatorio da Atividade #1}

\author{\IEEEauthorblockN{Barbara Caroline Benato}
\IEEEauthorblockA{
RA 192865\\
barbarabenato@gmail.com}
\and
\IEEEauthorblockN{Breno Leite}
\IEEEauthorblockA{
RA 190000\\
email address}}

\maketitle

\section{Introduç~ao}

A primeira tarefa da disciplina visava explorar a t´ecnica de regress~ao linear, a fim de encontrar o melhor modelo poss´ivel para um determinado problema evitando o overfitting do modelo, ou seja, que o modelo seja super treinado para o conjunto de dados dispon´ivel de tal forma que n~ao seja capaz de predizer para outros dados. Para tal tarefa, optou-se por predizer o ano de lançamento de de m´usica atrav´es de caracter´isticas espec´ificas de a´udio. Assim, varios modelos foram analisados utilizando uma validaç~ao cruzada para melhor an´alise dos dados. Uma abordagem de regress~ao linear utilizando a Equaç~ao Normal foi comparada com a utilizando o Gradiente Descendente.

\section{Atividades}
 
1. Perform Linear Regression (LR) as the baseline (first solution) and devise LR-based alternative (more
powerful) solutions.
2. Use the specified training/test data for providing your results and avoid overfitting.
3. Devise and test more complex models.
4. Plot the cost function vs. number of iterations in the training set and analyze the model complexity.
What are the conclusions? What are the actions after such analyses?
5. Use different Gradient Descent (GD) learning rates when optimizing. Compare the GD-based solutions
with Normal Equations if possible (perhaps you should try with smaller sample sizes for this task).
What are the conclusions?

\section{Materiais e M´etodos}

sklearn:
- pre processing: scale, normalize, pca
- metodos: LinearRegression e SGDRegressor
- base: subset of the Million Song Dataset (descrever)
- treino validaç~ao (validaç~ao cruzada) e teste
- metricas
- graficos: learning_curve e plot

\section{Experiments and Discussion}

Como a soluç~ao foi constru´ida a partir de um processo gradativo, optou-se por apresentar o desenvolvimento de tal processo.


\section{Conclusions and Future Work}

The main conclusions of the work as well as some future directions for other people interested in continuing this work. 

\begin{thebibliography}{00}
\bibitem{b1} Christopher M. Bishop. ``Pattern Recognition and Machine Learning''. Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006. 
\end{thebibliography}

\end{document}
